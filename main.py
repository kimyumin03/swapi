from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
import pickle
import pandas as pd
import numpy as np

app = FastAPI(title="ìƒê¶Œ ë¶„ì„ & ì¶”ì²œ API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

with open("model.pkl", "rb") as f:
    model = pickle.load(f)

merged_model = pd.read_pickle("merged_model.pkl")
merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…'] = merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…'].str.replace('?', '.', regex=False)

age_pop_cols = [
    'ì—°ë ¹ëŒ€_10_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_20_ìœ ë™ì¸êµ¬_ìˆ˜',
    'ì—°ë ¹ëŒ€_30_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_40_ìœ ë™ì¸êµ¬_ìˆ˜',
    'ì—°ë ¹ëŒ€_50_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ìœ ë™ì¸êµ¬_ìˆ˜'
]

def format_ratio(x):
    return f"{x:.5f}"

def format_money_mw(x):
    """
    ê¸ˆì•¡(x)ì„ ë§Œì› ë‹¨ìœ„ë¡œë§Œ ë°˜í™˜
    ex) 36000000 â†’ '3600'
    """
    return str(int(round(x / 10000)))

def format_income_mw(x):
    """
    ì›” í‰ê·  ì†Œë“(x)ì„ ë§Œì› ë‹¨ìœ„ë¡œ ë°˜í™˜
    ex) 3600000 â†’ '360'
    """
    return str(int(round(x / 10000)))

# =========================
# 16) ë¦¬íŒ©í† ë§ëœ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
# =========================

def generate_result_template(merged_model, í–‰ì •ë™ëª…):
    ë“±ê¸‰_í…ìŠ¤íŠ¸ = {0: 'í•˜', 1: 'ì¤‘', 2: 'ìƒ'}
    ë“±ê¸‰_info = {
        'ìƒ': {'desc': 'ë§¤ìš° ë†’ìŒ', 'precision': '77%', 'recommendations': ['ì¹´í˜', 'í—¬ìŠ¤ì¥', 'ë¯¸ìš©ì‹¤']},
        'ì¤‘': {'desc': 'ë³´í†µ', 'precision': '62%', 'recommendations': ['í¸ì˜ì ', 'ë¶„ì‹ì§‘', 'ì„¸íƒì†Œ']},
        'í•˜': {'desc': 'ë‚®ìŒ', 'precision': '69%', 'recommendations': ['ì¤‘ê³ ë§¤ì¥', 'PCë°©', 'í˜¸í”„ì§‘']}
    }

    filtered = merged_model[merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…'] == í–‰ì •ë™ëª…].copy()
    if filtered.empty:
        return f"âŒ '{í–‰ì •ë™ëª…}'ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    filtered['ì˜ˆì¸¡_ë“±ê¸‰_í…ìŠ¤íŠ¸'] = filtered['ì˜ˆì¸¡_ë“±ê¸‰'].map(ë“±ê¸‰_í…ìŠ¤íŠ¸)
    summary = filtered[['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…', 'ì˜ˆì¸¡_ë“±ê¸‰_í…ìŠ¤íŠ¸']].drop_duplicates()
    top_grade = summary['ì˜ˆì¸¡_ë“±ê¸‰_í…ìŠ¤íŠ¸'].value_counts().idxmax()
    info = ë“±ê¸‰_info[top_grade]

    ì„œìš¸ì‹œ = merged_model
    ì„œìš¸ì‹œ_avg_flow = ì„œìš¸ì‹œ['ìœ ë™ì¸êµ¬_ë³€í™”ìœ¨'].mean()
    ì„œìš¸ì‹œ_avg_yoy_pop = ì„œìš¸ì‹œ['ì „ë…„ë™ê¸°_ìœ ë™ì¸êµ¬_ë³€í™”ìœ¨'].mean()
    ì„œìš¸ì‹œ_avg_sales = ì„œìš¸ì‹œ['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'].mean()
    ì„œìš¸ì‹œ_avg_yoy_sales = ì„œìš¸ì‹œ['ì „ë…„ë™ê¸°_ë§¤ì¶œ_ë³€í™”ìœ¨'].mean()
    ì„œìš¸ì‹œ_avg_income = ì„œìš¸ì‹œ['ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡'].mean()

    ì§€ì—­_avg_flow = filtered['ìœ ë™ì¸êµ¬_ë³€í™”ìœ¨'].mean()
    ì§€ì—­_avg_yoy_pop = filtered['ì „ë…„ë™ê¸°_ìœ ë™ì¸êµ¬_ë³€í™”ìœ¨'].mean()
    ì§€ì—­_avg_sales = filtered['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'].mean()
    ì§€ì—­_avg_yoy_sales = filtered['ì „ë…„ë™ê¸°_ë§¤ì¶œ_ë³€í™”ìœ¨'].mean()
    ì§€ì—­_avg_income = filtered['ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡'].mean()
    ì§€ì—­_count = filtered.shape[0]

    ë‚¨_ratio = filtered['ë‚¨ì„±_ìœ ë™ì¸êµ¬_ë¹„ìœ¨'].mean()
    ì—¬_ratio = filtered['ì—¬ì„±_ìœ ë™ì¸êµ¬_ë¹„ìœ¨'].mean()
    ì£¼ì„±ë³„ = 'ë‚¨ì„±' if ë‚¨_ratio >= ì—¬_ratio else 'ì—¬ì„±'

    ì—°ë ¹ëŒ€ë³„ë¹„ìœ¨_cols = [f"{col}_ë¹„ìœ¨" for col in age_pop_cols]
    avg_age_ratios = filtered[ì—°ë ¹ëŒ€ë³„ë¹„ìœ¨_cols].mean()
    ì£¼ì—°ë ¹ëŒ€ = avg_age_ratios.idxmax().replace('_ë¹„ìœ¨', '')

    peak_time = filtered['ìµœëŒ€_ì‹œê°„ëŒ€_ì´ë¦„'].mode().iloc[0]

    reasons = []
    # 1) ìœ ë™ì¸êµ¬ ë³€í™”ìœ¨ ë¹„êµ
    if ì§€ì—­_avg_flow > ì„œìš¸ì‹œ_avg_flow:
        reasons.append(
            f"ìœ ë™ì¸êµ¬ ë³€í™”ìœ¨ì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤ ({format_ratio(ì§€ì—­_avg_flow)} > {format_ratio(ì„œìš¸ì‹œ_avg_flow)})."
        )
    else:
        reasons.append(
            f"ìœ ë™ì¸êµ¬ ë³€í™”ìœ¨ì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤ ({format_ratio(ì§€ì—­_avg_flow)} < {format_ratio(ì„œìš¸ì‹œ_avg_flow)})."
        )
    # 2) ì „ë…„ ë™ê¸° ëŒ€ë¹„ ìœ ë™ì¸êµ¬ ë³€í™”ìœ¨ â€œì¶”ì„¸â€
    if np.isclose(ì§€ì—­_avg_yoy_pop, ì„œìš¸ì‹œ_avg_yoy_pop):
        reasons.append("ì „ë…„ ë™ê¸° ëŒ€ë¹„ ìœ ë™ì¸êµ¬ ë³€í™”ê°€ ì„œìš¸ì‹œ í‰ê· ê³¼ ìœ ì‚¬í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
    elif ì§€ì—­_avg_yoy_pop > ì„œìš¸ì‹œ_avg_yoy_pop:
        reasons.append("ì „ë…„ ë™ê¸° ëŒ€ë¹„ ìœ ë™ì¸êµ¬ê°€ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ì¦ê°€ ì¶”ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤.")
    else:
        reasons.append("ì „ë…„ ë™ê¸° ëŒ€ë¹„ ìœ ë™ì¸êµ¬ê°€ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ê°ì†Œ ì¶”ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤.")
    # 3) í˜„ì¬ ë§¤ì¶œ ë¹„êµ
    if ì§€ì—­_avg_sales > ì„œìš¸ì‹œ_avg_sales:
        reasons.append(
            f"í˜„ì¬(ë‹¹ì›”) í‰ê·  ë§¤ì¶œì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤ ({format_money_mw(ì§€ì—­_avg_sales)}ë§Œ ì› > {format_money_mw(ì„œìš¸ì‹œ_avg_sales)}ë§Œ ì›)."
        )
    else:
        reasons.append(
            f"í˜„ì¬(ë‹¹ì›”) í‰ê·  ë§¤ì¶œì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤ ({format_money_mw(ì§€ì—­_avg_sales)}ë§Œ ì› < {format_money_mw(ì„œìš¸ì‹œ_avg_sales)}ë§Œ ì›)."
        )
    # 4) ì „ë…„ ë™ê¸° ëŒ€ë¹„ ë§¤ì¶œ ë³€í™”ìœ¨ â€œì¶”ì„¸â€
    if np.isclose(ì§€ì—­_avg_yoy_sales, ì„œìš¸ì‹œ_avg_yoy_sales):
        reasons.append("ì „ë…„ ë™ê¸° ëŒ€ë¹„ ë§¤ì¶œ ë³€í™”ê°€ ì„œìš¸ì‹œ í‰ê· ê³¼ ìœ ì‚¬í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
    elif ì§€ì—­_avg_yoy_sales > ì„œìš¸ì‹œ_avg_yoy_sales:
        reasons.append("ì „ë…„ ë™ê¸° ëŒ€ë¹„ ë§¤ì¶œì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ìƒìŠ¹ ì¶”ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤.")
    else:
        reasons.append("ì „ë…„ ë™ê¸° ëŒ€ë¹„ ë§¤ì¶œì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ í•˜ë½ ì¶”ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤.")
    # 5) í‰ê·  ì†Œë“ ë¹„êµ (ë‹¨ìœ„: ë§Œì›)
    if ì§€ì—­_avg_income > ì„œìš¸ì‹œ_avg_income:
        reasons.append(
            f"ì›” í‰ê·  ì†Œë“ì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤ ({format_income_mw(ì§€ì—­_avg_income)}ë§Œ ì› > {format_income_mw(ì„œìš¸ì‹œ_avg_income)}ë§Œ ì›)."
        )
    else:
        reasons.append(
            f"ì›” í‰ê·  ì†Œë“ì´ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤ ({format_income_mw(ì§€ì—­_avg_income)}ë§Œ ì› < {format_income_mw(ì„œìš¸ì‹œ_avg_income)}ë§Œ ì›)."
        )
    # 6) ë°ì´í„° ê±´ìˆ˜ ë¹„êµ
    ì„œìš¸ì‹œ_avg_count = ì„œìš¸ì‹œ.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…').size().mean()
    if ì§€ì—­_count > ì„œìš¸ì‹œ_avg_count:
        reasons.append(
            f"ì´ ì§€ì—­ ë°ì´í„° ê±´ìˆ˜ê°€ í‰ê· ë³´ë‹¤ ë§ì•„ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤ ({ì§€ì—­_count}ê°œ > {ì„œìš¸ì‹œ_avg_count:.1f}ê°œ)."
        )
    else:
        reasons.append(
            f"ì´ ì§€ì—­ ë°ì´í„° ê±´ìˆ˜ê°€ í‰ê· ë³´ë‹¤ ì ì–´ ë°ì´í„°ê°€ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ({ì§€ì—­_count}ê°œ < {ì„œìš¸ì‹œ_avg_count:.1f}ê°œ)."
        )

    # ë™ì  Top3 ì—…ì¢… ì¶”ì²œ
    ì—…ì¢…ë³„_avg_future = (
        filtered
        .groupby('ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…')['í–¥í›„_í‰ê· _ë§¤ì¶œ']
        .mean()
        .sort_values(ascending=False)
    )
    top3_ì—…ì¢… = ì—…ì¢…ë³„_avg_future.head(3).index.tolist()

    fixed_reco = ë“±ê¸‰_info[top_grade]['recommendations']

    output = f"""
ğŸ” '{í–‰ì •ë™ëª…}' ìƒê¶Œ ë¶„ì„ ê²°ê³¼
ì˜ˆì¸¡ ëª¨ë¸ì— ë”°ë¥´ë©´ ì´ ì§€ì—­ì€ ì°½ì—… ì í•©ë„ ë“±ê¸‰ '{top_grade}' ({info['desc']})ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ì—…ì¢…ì´ ê°€ì¥ ë§ìŠµë‹ˆë‹¤.
ì´ëŠ” ì„œìš¸ì‹œ ìƒê¶Œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ë™ì¸êµ¬ ë³€í™”, ë§¤ì¶œ íë¦„, ì†Œë“ ìˆ˜ì¤€ ë“± ë‹¤ì–‘í•œ ì§€í‘œë¥¼ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

- ëª¨ë¸ ì „ì²´ ì •í™•ë„ëŠ” 71%ì´ë©°, '{top_grade}' ë“±ê¸‰ ì˜ˆì¸¡ ì •ë°€ë„ëŠ” ì•½ {info['precision']}ì…ë‹ˆë‹¤.

ğŸ“Œ ë¶„ë¥˜ëœ ì£¼ìš” ì´ìœ :
"""
    for reason in reasons:
        output += f"- {reason}\n"

    output += f"""
ğŸ”¹ ì£¼ìš” ê³ ê°ì¸µ ë° í”¼í¬ ì‹œê°„ëŒ€:
- ì£¼ìš” ê³ ê° ì„±ë³„: {ì£¼ì„±ë³„}
- ì£¼ìš” ê³ ê° ì—°ë ¹ëŒ€: {ì£¼ì—°ë ¹ëŒ€.replace('ì—°ë ¹ëŒ€_', '').replace('_ìœ ë™ì¸êµ¬_ìˆ˜', '')}ëŒ€
- í”¼í¬ ë§¤ì¶œ ì‹œê°„ëŒ€: {peak_time}

âœ… '{í–‰ì •ë™ëª…}' ì§€ì—­ ë™ì  ì¶”ì²œ ì—…ì¢… Top 3:
1. {top3_ì—…ì¢…[0]}
2. {top3_ì—…ì¢…[1]}
3. {top3_ì—…ì¢…[2]}

ğŸ”¹ '{top_grade}' ë“±ê¸‰ì— ì†í•  ë•Œ ì¶”ì²œ ì—…ì¢…:
"""
    for idx, ì—…ì¢… in enumerate(fixed_reco, start=1):
        output += f"{idx}. {ì—…ì¢…}\n"

    return output.strip()

def format_money_eokman(x):
    """
    ì› ë‹¨ìœ„ ê¸ˆì•¡(x)ì„ '000ì–µ 0000ë§Œ' í˜•íƒœë¡œ ë°˜í™˜
    ë‚´ë¶€ì ìœ¼ë¡œ 1ë§Œ ì› ë‹¨ìœ„ ê³¼ë„ ì ìš© ì‹œ ë³´ì •í•©ë‹ˆë‹¤.
    ex) 113018800000 â†’ '1130ì–µ 1883ë§Œ'
    """
    # ë§Œì› ë‹¨ìœ„ ê³¼ë„ ì ìš© ë³´ì •
    val_corrected = x // 10000
    val = int(round(val_corrected))
    # ì–µ ë‹¨ìœ„(100,000,000ì›)
    eok = val // 100_000_000
    man = (val % 100_000_000) // 10_000
    return f"{eok}ì–µ {man:04d}ë§Œ"

# =========================
# ìƒë“±ê¸‰ ì¶”ì²œ í•¨ìˆ˜
# =========================
def recommend_for_top_grade_v3_updated(merged_model, í–‰ì •ë™ëª…, top_n=5):
    # ëŒ€ìƒ í–‰ì •ë™ í•„í„°ë§
    filtered = merged_model[merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…'] == í–‰ì •ë™ëª…]
    if filtered.empty:
        raise ValueError(f"'{í–‰ì •ë™ëª…}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    # Top1 ì—…ì¢…
    top1 = (filtered.groupby('ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…')['í–¥í›„_í‰ê· _ë§¤ì¶œ']
            .mean().sort_values(ascending=False).index[0])
    results = {'Top1_ì—…ì¢…': top1}

    # 2(a) í•´ë‹¹ ì—…ì¢… ìƒë“±ê¸‰ ë§¤ì¶œ ìƒìœ„
    df_top = merged_model[(merged_model['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'] == top1) &
                          (merged_model['ì˜ˆì¸¡_ë“±ê¸‰'] == 2)]
    top_by_sales = pd.DataFrame(columns=['í–‰ì •ë™','í‰ê·  í–¥í›„ ë§¤ì¶œ'])
    if not df_top.empty:
        tmp = (df_top.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…')['í–¥í›„_í‰ê· _ë§¤ì¶œ']
               .mean().sort_values(ascending=False)
               .drop(index=í–‰ì •ë™ëª…, errors='ignore')
               .head(top_n)
               .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™','í–¥í›„_í‰ê· _ë§¤ì¶œ':'í‰ê·  í–¥í›„ ë§¤ì¶œ(Raw)'})
        )
        tmp['í‰ê·  í–¥í›„ ë§¤ì¶œ'] = tmp['í‰ê·  í–¥í›„ ë§¤ì¶œ(Raw)'].map(format_money_eokman)
        top_by_sales = tmp[['í–‰ì •ë™','í‰ê·  í–¥í›„ ë§¤ì¶œ']]
        top_by_sales.index = range(1, len(top_by_sales)+1)
    results['ìƒë“±ê¸‰_í–¥í›„ë§¤ì¶œ_ì¶”ì²œ'] = top_by_sales

    # 2(b) í”¼í¬ ì‹œê°„ëŒ€ ìœ ë™ì¸êµ¬ ìƒìœ„
    df_peak = merged_model[(merged_model['ì˜ˆì¸¡_ë“±ê¸‰']==2)&
                           (merged_model['ìµœëŒ€_ì‹œê°„ëŒ€_ì´ë¦„']=='ì‹œê°„ëŒ€_17~21')]
    peak_top = pd.DataFrame(columns=['í–‰ì •ë™','ê±´ìˆ˜'])
    if not df_peak.empty:
        tmp = (df_peak.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…').size()
               .sort_values(ascending=False)
               .drop(index=í–‰ì •ë™ëª…, errors='ignore')
               .head(top_n)
               .reset_index(name='ê±´ìˆ˜').rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™'})
        )
        tmp.index = range(1, len(tmp)+1)
        peak_top = tmp
    results['ìƒë“±ê¸‰_í”¼í¬ìœ ë™ì¸êµ¬_ì¶”ì²œ'] = peak_top

    # 3) ì „ì²´ ìƒë“±ê¸‰ ë¹„ìœ¨ ì¶”ì²œ
    grade_counts = (merged_model.groupby(['í–‰ì •ë™_ì½”ë“œ_ëª…','ì˜ˆì¸¡_ë“±ê¸‰'])['ì˜ˆì¸¡_ë“±ê¸‰']
                   .count().unstack(fill_value=0))
    grade_counts['ë°ì´í„° ê±´ìˆ˜'] = grade_counts.sum(axis=1)
    grade_counts['ë¹„ìœ¨(%)'] = grade_counts.get(2,0)/grade_counts['ë°ì´í„° ê±´ìˆ˜']*100
    overall = (grade_counts.sort_values('ë¹„ìœ¨(%)',ascending=False)
               .drop(index=í–‰ì •ë™ëª…,errors='ignore')
               .head(top_n)
               .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™'})
    )
    overall = overall[['í–‰ì •ë™','ë°ì´í„° ê±´ìˆ˜','ë¹„ìœ¨(%)']]
    overall['ë¹„ìœ¨(%)'] = overall['ë¹„ìœ¨(%)'].map(lambda x:f"{x:.2f}%")
    overall.index = range(1, len(overall)+1)
    results['ì¶”ê°€_ìƒë“±ê¸‰_ë¹„ìœ¨_ì¶”ì²œ'] = overall

    return results

# =========================
# ì¤‘ë“±ê¸‰ ì¶”ì²œ í•¨ìˆ˜
# =========================
def recommend_for_mid_grade_growth(merged_model, í–‰ì •ë™ëª…, top_n=5):
    filtered = merged_model[merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…']==í–‰ì •ë™ëª…]
    if filtered.empty:
        raise ValueError(f"'{í–‰ì •ë™ëª…}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    df_mid = merged_model[merged_model['ì˜ˆì¸¡_ë“±ê¸‰']==1]

    sales_growth = (df_mid.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…')['ë§¤ì¶œ_ë³€í™”ìœ¨']
                    .mean().sort_values(ascending=False)
                    .drop(index=í–‰ì •ë™ëª…,errors='ignore')
                    .head(top_n)
                    .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™','ë§¤ì¶œ_ë³€í™”ìœ¨':'í‰ê·  ë§¤ì¶œ ì¦ê°€ìœ¨'})
    )
    sales_growth.index = range(1,len(sales_growth)+1)

    pop_growth = (df_mid.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…')['ì „ë…„ë™ê¸°_ìœ ë™ì¸êµ¬_ë³€í™”ìœ¨']
                  .mean().sort_values(ascending=False)
                  .drop(index=í–‰ì •ë™ëª…,errors='ignore')
                  .head(top_n)
                  .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™','ì „ë…„ë™ê¸°_ìœ ë™ì¸êµ¬_ë³€í™”ìœ¨':'í‰ê·  ìœ ë™ì¸êµ¬ ì¦ê°€ìœ¨'})
    )
    pop_growth.index = range(1,len(pop_growth)+1)

    return {'ì¤‘ë“±ê¸‰_ë§¤ì¶œì¦ê°€_ì¶”ì²œ':sales_growth,'ì¤‘ë“±ê¸‰_ìœ ë™ì¸êµ¬ì¦ê°€_ì¶”ì²œ':pop_growth}

# =========================
# í•˜ë“±ê¸‰ ì¶”ì²œ í•¨ìˆ˜
# =========================
def recommend_for_low_grade_risk(merged_model, í–‰ì •ë™ëª…, top_n=5):
    filtered = merged_model[merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…']==í–‰ì •ë™ëª…]
    if filtered.empty:
        raise ValueError(f"'{í–‰ì •ë™ëª…}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    df_low = merged_model[merged_model['ì˜ˆì¸¡_ë“±ê¸‰']==0]

    # 1) íì—… ìœ„í—˜
    closure_risk = pd.DataFrame(columns=['í–‰ì •ë™','í‰ê·  ì˜ì—… ê°œì›”'])
    if 'íì—…_ì˜ì—…_ê°œì›”_í‰ê· ' in df_low and not df_low.empty:
        tmp = (df_low.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…')['íì—…_ì˜ì—…_ê°œì›”_í‰ê· ']
               .mean().round(1).sort_values()
               .drop(index=í–‰ì •ë™ëª…,errors='ignore').head(top_n)
               .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™','íì—…_ì˜ì—…_ê°œì›”_í‰ê· ':'í‰ê·  ì˜ì—… ê°œì›”'})
        )
        tmp.index = range(1,len(tmp)+1)
        closure_risk = tmp

    # 2) ì†Œë“ ë‚®ìŒ
    income_low = pd.DataFrame(columns=['í–‰ì •ë™','í‰ê·  ì†Œë“'])
    if 'ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡' in df_low and not df_low.empty:
        tmp2 = (df_low.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…')['ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡']
                .mean().sort_values()
                .drop(index=í–‰ì •ë™ëª…,errors='ignore').head(top_n)
                .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™','ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡':'í‰ê·  ì†Œë“(Raw)'})
        )
        tmp2['í‰ê·  ì†Œë“'] = tmp2['í‰ê·  ì†Œë“(Raw)'].floordiv(10000).astype(int).astype(str)+'ë§Œ ì›'
        income_low = tmp2[['í–‰ì •ë™','í‰ê·  ì†Œë“']]
        income_low.index = range(1,len(income_low)+1)

    # 3) ë§¤ì¶œ ë‚®ìŒ
    sales_low = pd.DataFrame(columns=['í–‰ì •ë™','í‰ê·  ë§¤ì¶œ'])
    if 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡' in df_low and not df_low.empty:
        tmp3 = (df_low.groupby('í–‰ì •ë™_ì½”ë“œ_ëª…')['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']
                .mean().sort_values()
                .drop(index=í–‰ì •ë™ëª…,errors='ignore').head(top_n)
                .reset_index().rename(columns={'í–‰ì •ë™_ì½”ë“œ_ëª…':'í–‰ì •ë™','ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡':'í‰ê·  ë§¤ì¶œ(Raw)'})
        )
        tmp3['í‰ê·  ë§¤ì¶œ'] = tmp3['í‰ê·  ë§¤ì¶œ(Raw)'].map(format_money_eokman)
        sales_low = tmp3[['í–‰ì •ë™','í‰ê·  ë§¤ì¶œ']]
        sales_low.index = range(1,len(sales_low)+1)

    return {'í•˜ë“±ê¸‰_íì—…ìœ„í—˜_ì¶”ì²œ':closure_risk,
            'í•˜ë“±ê¸‰_ì†Œë“ë‚®ì€_ì¶”ì²œ':income_low,
            'í•˜ë“±ê¸‰_ë§¤ì¶œë‚®ì€_ì¶”ì²œ':sales_low}

# =========================
# ì „ì²´ ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜
# =========================
def print_recommendation_report(merged_model, í–‰ì •ë™ëª…, top_n=5):
    filtered = merged_model[merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…']==í–‰ì •ë™ëª…]
    if filtered.empty:
        raise ValueError(f"'{í–‰ì •ë™ëª…}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    local_grade = int(filtered['ì˜ˆì¸¡_ë“±ê¸‰'].mode().iloc[0])

    if local_grade==2:
        top = recommend_for_top_grade_v3_updated(merged_model,í–‰ì •ë™ëª…,top_n)
        print(f"â–¶ Top1 ì—…ì¢…: {top['Top1_ì—…ì¢…']}\n")
        print(f"â–¶ ìƒë“±ê¸‰ ë§¤ì¶œ ìƒìœ„ {top_n}ê°œ:")
        print(top['ìƒë“±ê¸‰_í–¥í›„ë§¤ì¶œ_ì¶”ì²œ'],"\n")
        print(f"â–¶ í”¼í¬ ì‹œê°„ëŒ€ ìœ ë™ì¸êµ¬ ìƒìœ„ {top_n}ê°œ:")
        print(top['ìƒë“±ê¸‰_í”¼í¬ìœ ë™ì¸êµ¬_ì¶”ì²œ'],"\n")
        print(f"â–¶ ìƒë“±ê¸‰ ë¹„ìœ¨ ìƒìœ„ {top_n}ê°œ(ì¤‘ë³µì œì™¸):")
        print(top['ì¶”ê°€_ìƒë“±ê¸‰_ë¹„ìœ¨_ì¶”ì²œ'],"\n")
    elif local_grade==1:
        mid = recommend_for_mid_grade_growth(merged_model,í–‰ì •ë™ëª…,top_n)
        print(f"â–¶ ì¤‘ë“±ê¸‰ ë§¤ì¶œ ì¦ê°€ìœ¨ ìƒìœ„ {top_n}ê°œ (ìê¸° ì œì™¸):")
        print(mid['ì¤‘ë“±ê¸‰_ë§¤ì¶œì¦ê°€_ì¶”ì²œ'],"\n")
        print(f"â–¶ ì¤‘ë“±ê¸‰ ìœ ë™ì¸êµ¬ ì¦ê°€ìœ¨ ìƒìœ„ {top_n}ê°œ (ìê¸° ì œì™¸):")
        print(mid['ì¤‘ë“±ê¸‰_ìœ ë™ì¸êµ¬ì¦ê°€_ì¶”ì²œ'],"\n")
    else:
        low = recommend_for_low_grade_risk(merged_model,í–‰ì •ë™ëª…,top_n)
        print(f"â–¶ í•˜ë“±ê¸‰ íì—… ìœ„í—˜ ìƒìœ„ {top_n}ê°œ (ì˜ì—… ê°œì›” ì§§ì€ ìˆœ):")
        print(low['í•˜ë“±ê¸‰_íì—…ìœ„í—˜_ì¶”ì²œ'],"\n")
        print(f"â–¶ í•˜ë“±ê¸‰ ì†Œë“ ë‚®ì€ ìˆœ ìƒìœ„ {top_n}ê°œ:")
        print(low['í•˜ë“±ê¸‰_ì†Œë“ë‚®ì€_ì¶”ì²œ'],"\n")
        print(f"â–¶ í•˜ë“±ê¸‰ ë§¤ì¶œ ë‚®ì€ ìˆœ ìƒìœ„ {top_n}ê°œ:")
        print(low['í•˜ë“±ê¸‰_ë§¤ì¶œë‚®ì€_ì¶”ì²œ'],"\n")

@app.get("/")
def health_check():
    return {"status": "ok", "message": "ìƒê¶Œ ë¶„ì„ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}

@app.get("/predict")
def predict(dong_name: str = Query(..., description="ì˜ˆì¸¡í•  í–‰ì •ë™ëª… ì…ë ¥ ì˜ˆ: ì—­ì‚¼1ë™")):
    try:
        result_text = generate_result_template(merged_model, dong_name)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    return {"result": result_text} 

@app.get("/recommend/all")
def recommend_all(
    dong_name: str = Query(..., description="ì¶”ì²œ ê¸°ì¤€ í–‰ì •ë™ëª…"),
    top_n:    int   = Query(5,   description="ì¶”ì²œ ìƒìœ„ Nê°œ")
):
    base = merged_model[merged_model['í–‰ì •ë™_ì½”ë“œ_ëª…'] == dong_name]
    if base.empty:
        raise HTTPException(status_code=404, detail=f"'{dong_name}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        grade = int(base['ì˜ˆì¸¡_ë“±ê¸‰'].mode().iloc[0])
    except:
        raise HTTPException(status_code=500, detail="ì˜ˆì¸¡ ë“±ê¸‰ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    response = {"ë“±ê¸‰": grade}

    try:
        if grade == 2:
            result = recommend_for_top_grade_v3_updated(merged_model, dong_name, top_n)
            response.update({
                "ì¶”ì²œ_ê¸°ì¤€": "ìƒë“±ê¸‰",
                "Top1_ì—…ì¢…": result['Top1_ì—…ì¢…'],
                "í–¥í›„ë§¤ì¶œ_ìƒìœ„": result['ìƒë“±ê¸‰_í–¥í›„ë§¤ì¶œ_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
                "í”¼í¬ìœ ë™ì¸êµ¬_ìƒìœ„": result['ìƒë“±ê¸‰_í”¼í¬ìœ ë™ì¸êµ¬_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
                "ìƒë“±ê¸‰_ë¹„ìœ¨_ìƒìœ„": result['ì¶”ê°€_ìƒë“±ê¸‰_ë¹„ìœ¨_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
            })
        elif grade == 1:
            result = recommend_for_mid_grade_growth(merged_model, dong_name, top_n)
            response.update({
                "ì¶”ì²œ_ê¸°ì¤€": "ì¤‘ë“±ê¸‰",
                "ë§¤ì¶œì¦ê°€_ìƒìœ„": result['ì¤‘ë“±ê¸‰_ë§¤ì¶œì¦ê°€_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
                "ìœ ë™ì¸êµ¬ì¦ê°€_ìƒìœ„": result['ì¤‘ë“±ê¸‰_ìœ ë™ì¸êµ¬ì¦ê°€_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
            })
        else:
            result = recommend_for_low_grade_risk(merged_model, dong_name, top_n)
            response.update({
                "ì¶”ì²œ_ê¸°ì¤€": "í•˜ë“±ê¸‰",
                "íì—…ìœ„í—˜_ìƒìœ„": result['í•˜ë“±ê¸‰_íì—…ìœ„í—˜_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
                "ì†Œë“ë‚®ì€_ìƒìœ„": result['í•˜ë“±ê¸‰_ì†Œë“ë‚®ì€_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
                "ë§¤ì¶œë‚®ì€_ìƒìœ„": result['í•˜ë“±ê¸‰_ë§¤ì¶œë‚®ì€_ì¶”ì²œ'].reset_index().to_dict(orient="records"),
            })
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    return response
